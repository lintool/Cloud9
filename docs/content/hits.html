<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>Cloud9: A MapReduce Library for Hadoop</title>
<style type="text/css" media="screen">@import url( ../style.css );</style>
</head>

<body>

<div id="wrap">
<div id="container" class="one-column" >

<!-- header START -->

<div id="header">
<div id="caption">
<h1 id="title" style="color: white;">Cloud<sup><small>9</small></sup></h1>
<div id="tagline">A MapReduce Library for Hadoop</div>
</div>

<div class="fixed"></div>

</div>

<!-- header END -->

<!-- navigation START -->

<div id="navigation">

<script type="text/javascript" src="menu.js">
</script>

<div class="fixed"></div>

</div>

<!-- navigation END -->



<!-- content START -->

<div id="content">



	<!-- main START -->

	<div id="main">


<!--- START MAIN CONTENT HERE -->

<h2>Design Patterns &amp; Algorithms &#187; HITS</h2>

<div class="post">
<div class="content">
  
<p>Cloud<sup><small>9</small></sup> contains a MapReduce
  implementation of <a href="http://www.cs.cornell.edu/home/kleinber/auth.pdf">Kleinberg's Hubs and Authorities algorithm</a>.</p>

<p>
  Please see the <a href="./pagerank.html">Cloud<sup><small>9</small></sup>PageRank
  documentation</a> for a description of the link graph structure used
  in Cloud<sup><small>9</small></sup>. As with PageRank, the HITS code was developed and tested
  against the ClueWeb09 link graph, but can also be run against the
  Wikipedia link graph. The PageRank implementation page <a
  href="./pagerank.html">describes</a> how to extract this link graph.
</p>
  
<p>The rest of this guide assumes you are working with the
ClueWeb09 link graph (as discussed in the PageRank paper).  Here are the
relevant driver classes for running HITS:</p>

<ul>

  <li><code>edu.umd.cloud9.example.hits.AFormatterWG</code></li>

  <li><code>edu.umd.cloud9.example.hits.HFormatterWG</code></li>

  <li><code>edu.umd.cloud9.example.hits.MergeFormattedRecords</code></li>
  
  <li><code>edu.umd.cloud9.example.hits.PartitionGraph</code></li>

  <li><code>edu.umd.cloud9.example.hits.HubsAndAuthorities</code></li>

  <li><code>edu.umd.cloud9.example.hits.HubsAndAuthoritiesSchimmy</code></li>

</ul>

<p>Below, we present step-by-step instructions for running the various
experiments.</p>

<h4>Preparing the input data</h4>

<h5>Format</h5>

<p>First, we take the plain-text graph structure and pack it into the
appropriate Hadoop data structures. This is accomplished using three
driver programs.</p>

<p>The first driver program
<code>edu.umd.cloud9.example.hits.AFormatterWG</code>
(<b>A</b>uthority<b>FormatterW</b>eb<b>G</b>raph) constructs a
serialized list
of nodes and their incoming links from the plain-text graph
structure. It
takes five command-line arguments:</p>

<ul>

  <li>[input-path]: input directory</li>
  <li>[output-path]: output directory</li>
  <li>[num-mappers]: number of mappers to use (may be overridden by
  Hadoop)</li>
  <li>[num-reducers]: number of reducers to use, also the number of
  output files</li>
  <li>[stoplist-path]: location of the stoplist file (must be
  provided, <a href="#stoplists">see below</a>)</li>

</ul>

<p>Here is a sample command-line
invocation:</p>

<pre>
hadoop jar cloud9.jar edu.umd.cloud9.example.hits.AFormatterWG \
     /shared/Wikipedia/graph/en20100130/ /tmp/mmcgrath/wiki/outa 500 500 /tmp/mmcgrath/wiki/toobig.txt
</pre>

<p>The second driver program
<code>edu.umd.cloud9.example.hits.HFormatterWG</code>
(<b>H</b>ub<b>FormatterW</b>eb<b>G</b>raph) constructs a
serialized list
of nodes and their outgoing links from the plain-text graph
structure. It
takes the same five command-line arguments:</p>

<ul>

  <li>[input-path]: input directory</li>
  <li>[output-path]: output directory</li>
  <li>[num-mappers]: number of mappers to use (may be overridden by
  Hadoop)</li>
  <li>[num-reducers]: number of reducers to use, also the number of
  output files</li>
  <li>[stoplist-path]: location of the stoplist file (must be
  provided, <a href="#stoplists">see below</a>)</li>

</ul>

<p>Here is a sample command-line
invocation:</p>

<pre>
hadoop jar cloud9.jar edu.umd.cloud9.example.hits.HFormatterWG \
     /shared/Wikipedia/graph/en20100130/ /tmp/mmcgrath/wiki/outh 500 500 /tmp/mmcgrath/wiki/toobig.txt
</pre>

<h5><a name="stoplists":>Stoplists</a></h5>
<p>
It may be desirable to exclude certain highly-linked nodes from the rank
calcuations in order to prevent them from slowing down execution of the
Hadoop job. You may supply the <code>AFormatterWG</code> and the <code>HFormatterWG</code> a list of nodeIDs to ignore
in a text file, with one nodeID listed per line. If you do not wish to
ignore any nodes, simply supply an empty file for this parameter. A
sample stoplist file for ClueWeb09 segment one can be seen <a href="./toobig.txt">here</a>.</p>

<h5>Merge</h5>

<p>The third driver program merges the output of the previous two jobs
into one set of output files. It takes five command line
arguments:</p>

<ul>
  <li>[hub-input-path]: input directory containing output of HFormatterWG</li>
  <li>[auth-input-path]: input directory  containing output of AFormatterWG</li>
  <li>[output-path]: output directory</li>
  <li>[num-mappers]: number of mappers to use (may be overridden by
  Hadoop)</li>
  <li>[num-reducers]: number of reducers to use, also the number of
  output files</li>
</ul>

<p>Here is a sample command-line
invocation:</p>

<pre>
hadoop jar cloud9.jar
edu.umd.cloud9.example.hits.MergeFormattedRecords \
    /tmp/mmcgrath/wiki/outh /tmp/mmcgrath/wiki/outa /tmp/mmcgrath/wiki/merged 500 500
</pre>

<h5>Partition</h5>

<p>Finally, we need to partition the graph.  The appropriate driver
program is <code>edu.umd.cloud9.example.hits.PartitionGraph</code>, which takes the
following command-line arguments:</p>

<ul>

  <li>[inputDir]: input directory</li>
  <li>[outputDir]: output directory</li>
  <li>[numPartitions]: number of partitions</li>
  <li>[useRange?]: 1 to user range partitioning or 0 otherwise</li>
  <li>[nodeCount]: number of nodes in the graph</li>

</ul>

<p>So, let's partition the graph both ways:</p>

<pre>
# hash partition the graph
hadoop fs -mkdir /tmp/mmcgrath/hits-hash

hadoop jar cloud9.jar edu.umd.cloud9.example.hits.PartitionGraph \
   /umd-lin/jimmylin/PageRankRecords /tmp/mmcgrath/hits-hash/iter0000 100 0 50220423

# range partition the graph
hadoop fs -mkdir /tmp/mmcgrath/hits-range

hadoop jar cloud9.jar edu.umd.cloud9.example.hits.PartitionGraph \
   /umd-lin/jimmylin/PageRankRecords /tmp/mmcgrath/hits-range/iter0000 100 1 50220423
</pre>

<p>We want to specify an output directory of the form
<code>/base/path/iter0000</code> because that's the convention of the
HITS driver program: the output of iteration <i>x</i> is stored in
a subdirectory named <code>iterXXXX</code>.</p>

<h4>Running HITS</h4>

<p>Once the input data is formatted properly, we can run HITS.  The
two HITS driver programs are:</p>

<ul>

  <li><code>edu.umd.cloud9.example.hits.HubsAndAuthorities</code> for
  the basic implementation: shuffles graph structure from iteration to
  iteration.</li>

  <li><code>edu.umd.cloud9.example.hits.HubsAndAuthoritiesSchimmy</code>
  for the Schimmy implementation: avoids graph structure shuffling.</li>

</ul>

<p>Both driver programs take the same command-line arguments:</p>

<ul>

  <li>[basePath]: the base path</li>
  <li>[numNodes]: number of nodes in the graph</li>
  <li>[start]: starting iteration</li>
  <li>[end]: ending iteration</li>
  <li>[useCombiner?]: 1 for using combiner, 0 for not</li>
  <li>[useInMapCombiner?]: 1 for using in-mapper combining, 0 for not</li>
  <li>[useRange?]: 1 for range partitioning, 0 for not</li>
  <li>[num Mappers]: number of mappers to use</li>
  <li>[numReducers]: number of reducers to use. This should remain
  constant between iterations</li>
  

</ul>

<p>Some notes:</p>

<ul>

<li>The starting and ending iterations will correspond to
paths <code>/base/path/iterXXXX</code>
and <code>/base/path/iterYYYY</code>.  As a example, if you specify 0
and 10 as the starting and ending iterations, the driver program will
start with the graph structure stored
at <code>/base/path/iter0000</code>; final results will be stored
at <code>/base/path/iter0010</code>.</li>

<li>As with PageRank, the driver program will
allow you to use both combiners and the in-mapper combining pattern, but
using both actually slows down the algorithm. So those bits should be considered exclusive.</li>

</ul>

<p>As in the PageRank, examples here is the command-line invocation of
the "best-practices" baseline:</p>

<pre>
# hash partitioning, basic implementation, +combiner
hadoop jar cloud9.jar edu.umd.cloud9.example.hits.HubsAndAuthorities \
   /tmp/mmcgrath/hits-hash 50220423 0 10 1 0 0 100 100
</pre>

<p>Here are some command-line invocations exercising some of the
patterns discussed in the <a href="./Lin_Schatz_MLG2010.pdf">Lin & Schatz paper</a>:</p>

<pre>
# hash partitioning, basic implementation, +IMC
hadoop jar cloud9.jar edu.umd.cloud9.example.hits.HubsAndAuthorities \
   /tmp/mmcgrath/hits-hash 50220423 0 10 0 1 0 500 500

# hash partitioning, Schimmy implementation, +IMC
hadoop jar cloud9.jar edu.umd.cloud9.example.hits.HubsAndAuthoritiesSchimmy \
   /tmp/mmcgrath/hits-hash 50220423 0 10 0 1 0 500 500

# range partitioning, basic implementation, +IMC
hadoop jar cloud9.jar edu.umd.cloud9.example.hits.HubsAndAuthorities \
   /tmp/mmcgrath/hits-range 50220423 0 10 0 1 1 500 500

# range partitioning, Schimmy implementation, +IMC
hadoop jar cloud9.jar edu.umd.cloud9.example.hits.HubsAndAuthoritiesSchimmy \
   /tmp/mmcgrath/PageRank-range 50220423 0 10 0 1 1 500 500
</pre>

<p>Please keep in mind that if you wish to perform experiments on the
ClueWeb09 data or a graph of similar size and structure, you
will probably want to make use of the stoplist feature in the data
formatting phase in order to
prevent the reducers in <code>AFormatterWG</code> and <code>HubsAndAuthorities</code> from crunching away forever on the few nodes of
extremely high in-degree. In experiments run on segment 1 of the
ClueWeb09 data, I found it useful to ignore all nodes with in-degree
greater than 100,000. The textfile containing these nodeIDs can be
found <a href="./toobig.txt">here</a>. The Wikipedia graph, however,
was small enough to render stoplists unneccessary. Your milage may vary
based on the size and power of your cluster. </p>

</div></div>


<!--- END MAIN CONTENT HERE -->

	</div>

	<!-- main END -->



		<div class="fixed"></div>

</div>

<!-- content END -->

<!-- footer START -->

<div id="footer">
<div id="copyright">
Last updated:
<script type="text/javascript">
<!--//
document.write(document.lastModified);
//-->
</script>
</div>

<div id="themeinfo">
Adapted from a WordPress Theme by <a href="http://www.neoease.com/">NeoEase</a>. Valid <a href="http://validator.w3.org/check?uri=referer">XHTML 1.1</a> and <a href="http://jigsaw.w3.org/css-validator/check/referer?profile=css3">CSS 3</a>.	</div>

</div>

<!-- footer END -->



</div>

<!-- container END -->

</div>

<!-- wrap END -->

</body>
</html>

