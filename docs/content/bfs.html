<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Cloud9: A Hadoop toolkit for working with big data</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Le styles -->
    <link href="../assets/css/bootstrap.css" rel="stylesheet">
    <link href="../assets/css/bootstrap-responsive.css" rel="stylesheet">
    <link href="../assets/css/docs.css" rel="stylesheet">
    <link href="../assets/js/google-code-prettify/prettify.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

  </head>

  <body data-spy="scroll" data-target=".bs-docs-sidebar">

    <!-- Navbar
    ================================================== -->
    <div class="navbar navbar-inverse navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <button type="button" class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <div class="nav-collapse collapse">
            <ul class="nav">
              <li class="">
                <a href="../../index.html">Home</a>
              </li>
              <li class="">
                <a href="../contents.html">Table of Contents</a>
              </li>
              <li class="">
                <a href="../api/index.html">API</a>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>

<!-- Subhead
================================================== -->
<header class="jumbotron subhead" id="overview">
  <div class="container">
    <h1>Cloud<sup>9</sup></h1>
    <p class="lead">A Hadoop toolkit for working with big data</p>
  </div>
</header>

  <div class="container">

<div class="page-header">
<h2>Reference Implementations: Parallel Breadth-First Search</h2>
</div>

<p>This page describes the Cloud<sup>9</sup> reference
implementation of parallel breadth-first search, as described in
Chapter 5 of <a href="http://mapreduce.me">Data-Intensive Text
Processing with MapReduce</a>.  Note that the book does not describe
more recently developed design patterns for graph algorithms;
see <a href="pagerank.html">this page</a> for more information.</p>

<p>We use a very simple text format for specifying the graph
structure. A graph with <i>n</i> nodes is represented in a text file
with <i>n</i> arbitrarily-ordered lines. Each line begins with a
nodeid (numeric identifier for the node), followed by its adjacency
list, which specifies neighbors reachable via outgoing edges. The
adjacency list is tab separated. Note that if a node does not contain
an outgoing edges, you still need a line in the file to represent it.
Here's a simple example (tab replaced with spaces for presentation
reasons):</p>

<pre class="code">
1    3    4
2    1
3
4    2    3
</pre>

<p>This represents a graph with four nodes: nodeid 1 points to 3 and
4; nodeid 2 points to 1, nodeid 3 is a dangling node (no neighbors);
and nodeid 4 points to nodes 2 and 3.</p>

<p>Here, we'll be running parallel breadth-first search on Wikipedia.
Refer to this page on <a href="wikipedia.html">working with
Wikipedia</a>.  It contains instructions for packing Wikipedia pages
from the raw XML distribution into block-compressed <code>SequenceFile</code>s for
convenient access. Briefly, here are the steps:</p>

<p>First, build a docno mapping, making sure that you include all
pages with the
<code>-keep_all</code> option:</p>

<pre class="code">
etc/hadoop-cluster.sh edu.umd.cloud9.collection.wikipedia.WikipediaDocnoMappingBuilder \
  -input /shared/collections/wikipedia/raw/enwiki-20121201-pages-articles \
  -output_file enwiki-20121201-docno.dat -wiki_language en -keep_all 
</pre>

<p>Next, repack the collection into block-compressed
<code>SequenceFile</code>s:</p>

<pre class="code">
etc/hadoop-cluster.sh edu.umd.cloud9.collection.wikipedia.RepackWikipedia \
  -input /shared/collections/wikipedia/raw/enwiki-20121201-pages-articles -output enwiki-20121201.block \
  -mapping_file enwiki-20121201-docno.dat -wiki_language en -compression_type block
</pre>

<p>Once you've done that, extract the link graph:</p>

<pre class="code">
etc/hadoop-cluster.sh edu.umd.cloud9.collection.wikipedia.graph.ExtractWikipediaLinkGraph \
  -input enwiki-20121201.block -edges_output enwiki-20121201.edges -adjacency_list_output enwiki-20121201.adj -num_partitions 10
</pre>

<p>From the counters you'll see:</p>

<pre class="code">
edu.umd.cloud9.collection.wikipedia.graph.ExtractWikipediaLinkGraph$GraphInfo
  EDGES=121762273
  TOTAL_VERTICES=12961996
  VERTICIES_WITH_OUTLINKS=10813673
</pre>

<p>Which provides some statistics on the size of the graph.</p>

<p>After extracting the link structure, we take the plain-text
representation and pack it into appropriate Hadoop data structures. At
the same time, we specify the source of the breadth-first search:</p>

<pre class="code">
etc/hadoop-cluster.sh edu.umd.cloud9.example.bfs.EncodeBfsGraph \
 -input enwiki-20121201.adj -output enwiki-20121201.bfs/iter0000 -src 12
</pre>

<p>We'll start from nodeid
12, <a href="http://en.wikipedia.org/wiki/Anarchism">Anarchism</a>,
which is the first full article in the dataset. The number of nodes in
the link graph is stored in a counter and can be read either from the
command line or from the jobtracker.</p>

<p>This handy program can be used to find all reachable nodes and
print them in plain text:</p>

<pre class="code">
etc/hadoop-cluster.sh edu.umd.cloud9.example.bfs.FindReachableNodes \
 -input enwiki-20121201.bfs/iter0000 -output enwiki-20121201.bfs-reachable/iter0000
</pre>

<p>As a sanity check, we see that only the source node is
reachable.</p>

<p>Now let's run one iteration of parallel breadth-first search:</p>

<pre class="code">
etc/hadoop-cluster.sh edu.umd.cloud9.example.bfs.IterateBfs \
 -input enwiki-20121201.bfs/iter0000 -output enwiki-20121201.bfs/iter0001 -num_partitions 10
</pre>

<p>The final argument is the number of partitions (ten in our case).
We can pull out and examine the reachable nodes:</p>

<pre class="code">
etc/hadoop-cluster.sh edu.umd.cloud9.example.bfs.FindReachableNodes \
 -input enwiki-20121201.bfs/iter0001 -output enwiki-20121201.bfs-reachable/iter0001
</pre>

<p>Running more iterations, we'll get the following results:</p>

<div style="width: 300px;">
<table class="table">
<thead>
<tr><td style="text-align:right"><b>Iteration</b></td>
    <td style="text-align:right"><b>Reachable nodes</b></td>
</thead>

<tr><td style="text-align:right"> 0</td><td style="text-align:right">        1</td></tr>
<tr><td style="text-align:right"> 1</td><td style="text-align:right">      573</td></tr>
<tr><td style="text-align:right"> 2</td><td style="text-align:right">   37,733</td></tr>
<tr><td style="text-align:right"> 3</td><td style="text-align:right">  845,452</td></tr>
<tr><td style="text-align:right"> 4</td><td style="text-align:right">3,596,247</td></tr>
<tr><td style="text-align:right"> 5</td><td style="text-align:right">5,236,564</td></tr>
<tr><td style="text-align:right"> 6</td><td style="text-align:right">5,640,663</td></tr>
<tr><td style="text-align:right"> 7</td><td style="text-align:right">5,719,546</td></tr>
<tr><td style="text-align:right"> 8</td><td style="text-align:right">5,738,196</td></tr>
<tr><td style="text-align:right"> 9</td><td style="text-align:right">5,742,452</td></tr>
<tr><td style="text-align:right">10</td><td style="text-align:right">5,743,930</td></tr>
<tr><td style="text-align:right">11</td><td style="text-align:right">5,744,670</td></tr>
<tr><td style="text-align:right">12</td><td style="text-align:right">5,744,969</td></tr>
<tr><td style="text-align:right">13</td><td style="text-align:right">5,745,165</td></tr>
<tr><td style="text-align:right">14</td><td style="text-align:right">5,745,283</td></tr>
<tr><td style="text-align:right">15</td><td style="text-align:right">5,745,373</td></tr>
<tr><td style="text-align:right">16</td><td style="text-align:right">5,745,439</td></tr>
<tr><td style="text-align:right">17</td><td style="text-align:right">5,745,488</td></tr>
<tr><td style="text-align:right">18</td><td style="text-align:right">5,745,533</td></tr>
<tr><td style="text-align:right">19</td><td style="text-align:right">5,745,570</td></tr>
<tr><td style="text-align:right">20</td><td style="text-align:right">5,745,608</td></tr>
<tr><td style="text-align:right">21</td><td style="text-align:right">5,745,642</td></tr>
<tr><td style="text-align:right">22</td><td style="text-align:right">5,745,663</td></tr>
<tr><td style="text-align:right">23</td><td style="text-align:right">5,745,683</td></tr>
<tr><td style="text-align:right">24</td><td style="text-align:right">5,745,699</td></tr>
<tr><td style="text-align:right">25</td><td style="text-align:right">5,745,711</td></tr>

</table>
</div>

<p>A few observations: only about 45% of Wikipedia pages are
reachable, but the vast majority of reachable pages are only a few
hops away.  But why are there pages so far away?  (The algorithm still
had not converged at iteration 25, but I gave up trying.)  To
investigate, we can use a handy tool to extract pages that are at a
specific distance (e.g., 25 hops away):</p>

<pre class="code">
etc/hadoop-cluster.sh edu.umd.cloud9.example.bfs.FindNodeAtDistance \
 -input enwiki-20121201.bfs/iter0025 -output enwiki-20121201.bfs-d/iter0025 -distance 25
</pre>

<p>As it turns out, there are really long chains of articles in
Wikipedia.  Here's an example:</p>

<ul>
<li>
<a href="http://en.wikipedia.org/wiki/Lenart_Praunsperger">Lenart Praunsperger</a> ::
<a href="http://en.wikipedia.org/wiki/Jakob_Stettenfelder">Jakob Stettenfelder</a> ::
<a href="http://en.wikipedia.org/wiki/Janez_Lindauer">Janez Lindauer</a> ::
<a href="http://en.wikipedia.org/wiki/Volk_Meditsch">Volk Meditsch</a> ::
<a href="http://en.wikipedia.org/wiki/Matevz_Frang">Matevz Frang</a> ::
<a href="http://en.wikipedia.org/wiki/Jurij_Tazel">Jurij Tazel</a> ::
<a href="http://en.wikipedia.org/wiki/Anton_Lantheri">Anton Lantheri</a> :: ...
</li>
</ul>

<p>What?! Digging around a bit, we find
that <a href="http://en.wikipedia.org/wiki/Lenart_Praunsperger">Lenart
Praunsperger</a> was the mayor
of <a href="http://en.wikipedia.org/wiki/Ljubljana">Ljubljana</a>
(Solvenia) in 1506.  His short bio page links to a page for each of
his successors, each of whom have a short bio page.</p>

<p>Another example:</p>


<ul>
 <li><a href="http://en.wikipedia.org/wiki/List_of_Peers_1060-1069">List of peers 1060–1069</a> ::
     <a href="http://en.wikipedia.org/wiki/List_of_Peers_1070-1079">List of peers 1070–1079</a> ::
     <a href="http://en.wikipedia.org/wiki/List_of_Peers_1080-1089">List of peers 1080–1089</a> ::
     <a href="http://en.wikipedia.org/wiki/List_of_Peers_1090-1099">List of peers 1090–1099</a> :: ...</li>
</ul>

<p>This goes on until the early 13th century...  So, no, there isn't a
bug in the code.  Wikipedia is simply idiosyncratic.</p>


  </div>



    <!-- Footer
    ================================================== -->
    <footer class="footer">
      <div class="container">
        <p class="pull-right"><a href="#">Back to top</a></p>
        <p>Designed using <a href="http://twitter.github.com/bootstrap/">Bootstrap</a>.</p>
        <p>Code licensed under <a href="http://www.apache.org/licenses/LICENSE-2.0" target="_blank">Apache License v2.0</a>, documentation under <a href="http://creativecommons.org/licenses/by/3.0/">CC BY 3.0</a>.</p>
      </div>
    </footer>

    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/js/jquery.js"></script>
    <script src="../assets/js/google-code-prettify/prettify.js"></script>
    <script src="../assets/js/bootstrap-transition.js"></script>
    <script src="../assets/js/bootstrap-alert.js"></script>
    <script src="../assets/js/bootstrap-modal.js"></script>
    <script src="../assets/js/bootstrap-dropdown.js"></script>
    <script src="../assets/js/bootstrap-scrollspy.js"></script>
    <script src="../assets/js/bootstrap-tab.js"></script>
    <script src="../assets/js/bootstrap-tooltip.js"></script>
    <script src="../assets/js/bootstrap-popover.js"></script>
    <script src="../assets/js/bootstrap-button.js"></script>
    <script src="../assets/js/bootstrap-collapse.js"></script>
    <script src="../assets/js/bootstrap-carousel.js"></script>
    <script src="../assets/js/bootstrap-typeahead.js"></script>
    <script src="../assets/js/bootstrap-affix.js"></script>

  </body>
</html>
